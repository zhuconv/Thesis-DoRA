{
    "os": "Linux-3.10.0-1160.el7.x86_64-x86_64-with-glibc2.31",
    "python": "3.10.14",
    "heartbeatAt": "2024-04-03T16:19:01.257875",
    "startedAt": "2024-04-03T16:19:00.102077",
    "docker": null,
    "gpu": "NVIDIA L40S",
    "gpu_count": 1,
    "cpu_count": 128,
    "cuda": null,
    "args": [
        "--train_samples",
        "10000",
        "--eval_samples",
        "64",
        "--custom_mode",
        "lora",
        "--lr",
        "4e-4",
        "--lora_r",
        "64",
        "--train_bs",
        "4",
        "--eval_bs",
        "4",
        "--custom_disable_identity",
        "--accumulation_steps",
        "4",
        "--model",
        "meta-llama/Llama-2-7b-hf",
        "--quantize",
        "--seed",
        "42",
        "--eval_steps",
        "20",
        "--logging_steps",
        "1",
        "--target_modules",
        "no_head",
        "--generate_samples",
        "--metrics_enabled",
        "0",
        "--lr_scheduler_type",
        "cosine",
        "--task",
        "instruct",
        "--dataset",
        "alpaca-clean",
        "--init_type",
        "1",
        "--d_init_type",
        "94",
        "--epochs",
        "1",
        "--dynamic_uv",
        "0",
        "--shared_dim",
        "11008",
        "--shared_uv",
        "0",
        "--offline"
    ],
    "state": "running",
    "program": "/zhujiajun/ThesisLoRA/repos/VeRA/instruct/finetune.py",
    "codePath": "finetune.py",
    "host": "8tcde31r6nba0-0",
    "username": "root",
    "executable": "/zhujiajun/miniconda3/envs/dora/bin/python"
}
